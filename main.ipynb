{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import important Libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "from timeit import default_timer as timer\n",
    "from tqdm.auto import tqdm\n",
    "from helper_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_0 = torchvision.transforms.Compose([torchvision.transforms.Grayscale(),\n",
    "                                            torchvision.transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.CIFAR10(root= \"data\", \n",
    "                                train=True, # get training data\n",
    "                                download=True, # download data if it doesn't exist on disk\n",
    "                                transform=transform_0, # images come as PIL format, we want to turn into Torch tensors\n",
    "                                target_transform=None) # you can transform labels as well)\n",
    "\n",
    "testing_data = datasets.CIFAR10(root= \"data\", \n",
    "                                train=False, # get training data\n",
    "                                download=True, # download data if it doesn't exist on disk\n",
    "                                transform=transform_0, # images come as PIL format, we want to turn into Torch tensors\n",
    "                                target_transform=None) # you can transform labels as well)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = training_data[100]\n",
    "image,label\n",
    "image.shape, training_data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot more images\n",
    "torch.manual_seed(42)\n",
    "fig = plt.figure(figsize=(9, 9))\n",
    "rows, cols = 4, 4\n",
    "for i in range(1, rows * cols + 1):\n",
    "    random_idx = torch.randint(0, len(training_data), size=[1]).item()\n",
    "    img, label = training_data[random_idx]\n",
    "    fig.add_subplot(rows, cols, i)\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "    plt.title(training_data.classes[label])\n",
    "    plt.axis(False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = DataLoader(testing_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f\"Dataloaders: {train_dataloader, test_dataloader}\") \n",
    "print(f\"Length of train dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}\")\n",
    "print(f\"Length of test dataloader: {len(test_dataloader)} batches of {BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images_batch, training_labels_batch = next(iter(train_dataloader))\n",
    "print(training_labels_batch)\n",
    "print(training_images_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show a sample\n",
    "torch.manual_seed(42)\n",
    "random_idx = torch.randint(0, len(training_images_batch), size=[1]).item()\n",
    "img, label = training_images_batch[random_idx], training_labels_batch[random_idx]\n",
    "plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.title(training_data.classes[label])\n",
    "plt.axis(\"Off\");\n",
    "print(f\"Image size: {img.shape}\")\n",
    "print(f\"Label: {label}, label size: {label.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import mnist10_modelv0\n",
    "torch.manual_seed(42)\n",
    "\n",
    "model_1 = mnist10_modelv0(\n",
    "    input_shape= training_images_batch.shape[2] * training_images_batch.shape[3],\n",
    "    output_shape= len(training_data.classes)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params = model_1.parameters(), lr = 0.2)\n",
    "\n",
    "# Setup device agnostic code\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model_1.to(device)\n",
    "next(model_1.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed and start the timer\n",
    "torch.manual_seed(42)\n",
    "train_time_start_on_gpu = timer()\n",
    "\n",
    "# Set the number of epochs (we'll keep this small for faster training times)\n",
    "epochs = 20\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch: {epoch+1}\\n---------\")\n",
    "    train_step(data_loader=train_dataloader, \n",
    "        model=model_1, \n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=optimizer,\n",
    "        accuracy_fn=accuracy_fn,\n",
    "        device = device\n",
    "    )\n",
    "    test_step(data_loader=test_dataloader,\n",
    "        model=model_1,\n",
    "        loss_fn=loss_fn,\n",
    "        accuracy_fn=accuracy_fn,\n",
    "        device = device\n",
    "    )\n",
    "\n",
    "train_time_end_on_gpu = timer()\n",
    "total_train_time_model_1 = print_train_time(start=train_time_start_on_gpu,\n",
    "                                            end=train_time_end_on_gpu,\n",
    "                                            device=device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = next(iter(test_dataloader))\n",
    "print(y,X[0].shape)\n",
    "y_pred = model_1(X.to(device)).argmax(dim=1)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9, 9))\n",
    "rows, cols = 4, 4\n",
    "for i in range(1, rows * cols + 1):\n",
    "    fig.add_subplot(rows,cols,i)\n",
    "    plt.imshow(X[i].squeeze(), cmap=\"gray\")\n",
    "    if training_data.classes[y[i]] != training_data.classes[y_pred[i]]:\n",
    "\n",
    "        plt.title(f\"{training_data.classes[y[i]]}/{training_data.classes[y_pred[i]]}\", color=\"red\")\n",
    "    else:\n",
    "        plt.title(f\"{training_data.classes[y[i]]}/{training_data.classes[y_pred[i]]}\", color = \"green\")\n",
    "\n",
    "    plt.axis(False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from models import mnistt10_CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "y_pred = y_pred.to('cpu')\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=training_data.classes, \n",
    "            yticklabels=training_data.classes)\n",
    "\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = mnistt10_CNN(input_shape=1,\n",
    "                        hidden_units=10,\n",
    "                        output_shape=len(training_data.classes)).to(device)\n",
    "\n",
    "model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params = model_2.parameters(), lr = 0.1, weight_decay=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test model \n",
    "epochs = 10\n",
    "train_time_start_model_2 = timer()\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch: {epoch}\\n---------\")\n",
    "    train_step(data_loader=train_dataloader, \n",
    "        model=model_2, \n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=optimizer,\n",
    "        accuracy_fn=accuracy_fn,\n",
    "        device=device\n",
    "    )\n",
    "    test_step(data_loader=test_dataloader,\n",
    "        model=model_2,\n",
    "        loss_fn=loss_fn,\n",
    "        accuracy_fn=accuracy_fn,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "train_time_end_model_2 = timer()\n",
    "total_train_time_model_2 = print_train_time(start=train_time_start_model_2,\n",
    "                                           end=train_time_end_model_2,\n",
    "                                           device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = next(iter(test_dataloader))\n",
    "print(y,X[0].shape)\n",
    "y_pred = model_2(X.to(device)).argmax(dim=1)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9, 9))\n",
    "rows, cols = 4, 4\n",
    "for i in range(1, rows * cols + 1):\n",
    "    fig.add_subplot(rows,cols,i)\n",
    "    plt.imshow(X[i].squeeze(), cmap=\"gray\")\n",
    "    if training_data.classes[y[i]] != training_data.classes[y_pred[i]]:\n",
    "\n",
    "        plt.title(f\"{training_data.classes[y[i]]}/{training_data.classes[y_pred[i]]}\", color=\"red\")\n",
    "    else:\n",
    "        plt.title(f\"{training_data.classes[y[i]]}/{training_data.classes[y_pred[i]]}\", color = \"green\")\n",
    "\n",
    "    plt.axis(False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = Path(\"models_dic\")\n",
    "\n",
    "# Create model save path\n",
    "MODEL_NAME = \"03_pytorch_computer_vision_model_2.pth\"\n",
    "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
    "\n",
    "# Save the model state dict\n",
    "print(f\"Saving model to: {MODEL_SAVE_PATH}\")\n",
    "torch.save(obj=model_2.state_dict(), # only saving the state_dict() only saves the learned parameters\n",
    "           f=MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
